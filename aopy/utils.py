# utils.py
# Any extra utility functions belong here
# Helper functions, math, other things that don't really pertain to neural data analysis

import numpy as np
import re
from datetime import datetime
import os

'''
Test signals
'''
def generate_test_signal(duration, samplerate, frequencies, amplitudes, noise_amplitude=0.):
    '''
    Generates a test time series signal with multiple frequencies, specified in freq, for T timelength at a sampling rate of fs

    Args:
        duration (float): time period in seconds
        samplerate (int): sampling frequency in Hz
        frequencies (1D array): list of frequencies to be mixed in the test signal
        amplitudes (1D array): list of amplitudes for each frequency
        noise_amplitude (float, optional): amplitude of noise added on top of test signal

    Returns:
        tuple: Tuple containing:
            | **x (1D array):** cosine wave with multiple frequencies (and noise)
            | **t (1D array):** time vector for x
    '''
    n_samples = int(duration * samplerate)
    t = np.linspace(0, duration, n_samples, endpoint=False)

    x = np.random.normal(0,noise_amplitude,n_samples) # start with some noise

    for i in range(len(frequencies)):
        x += amplitudes[i] * np.cos(2 * np.pi * frequencies[i] * t)

    return x, t

def generate_multichannel_test_signal(duration, samplerate, n_channels, frequency, amplitude):
    '''
    Generate sine waves offset in phase by 2*pi/n_channels at the given amplitude and frequency

    Args: 
        duration (float): time in seconds
        samplerate (int): sampling rate of the signal in Hz
        n_channels (int): number of channels to generate
        frequency (float): frequency in Hz
        amplitude (float): amplitude of each sine wave

    Returns:
        (nt, nch) array: timeseries data across channels
    '''    
    time = np.arange(0, duration, 1/samplerate)
    data = []
    for i in range(n_channels):
        theta = 2*i*np.pi/8 # shift phase for each channel
        sinewave = amplitude * np.sin(2 * np.pi * frequency * time + theta)
        data.append(sinewave)
    data = np.array(data).T

    return data

def save_test_signal_ecube(data, save_dir, voltsperbit, datasource='Headstages'):
    '''
    Create a binary file with eCube formatting using the given data

    Args:
        data (nt, nch): test_signal to save
        save_dir (str): where to save the file
        voltsperbit (float): gain of the data you are creating
        datasource (str): eCube source from which you want the data to be 
            labeled (i.e. Headstages, AnalogPanel, or DigitalPanel)

    Returns:
        str: filename of the new data
    '''
    intdata = np.array(data/voltsperbit, dtype='<i2') # turn into integer data
    flatdata = intdata.reshape(-1)
    timestamp = np.array([1, 2, 3, 4], dtype='<i2')

    # Save it to the test file
    datestr = datetime.now().strftime("%Y-%m-%d_%H-%M-%S") # e.g. 2021-05-06_11-47-02
    filename = f"{datasource}_{data.shape[1]}_Channels_int16_{datestr}.bin"
    filepath = os.path.join(save_dir, filename)
    with open(filepath, 'wb') as f:
        f.write(timestamp)
        f.write(flatdata.tobytes())

    return filename

def count_unique_symbols(files):
    '''
    Utility for counting how many times each unique symbol is listed in the given list
    and ranking them by descending number of uses.

    Args:
        files (list): list of filenames containing symbols generated by vscode 'List Symbols' 

    Returns:
        tuple: tuple containing:
            | **unique_symbols (list):** list of unique symbols
            | **counts (list):** list of counts for each unique symbol
    '''
    symbols = []
    for filename in files:
        with open(filename, mode='r') as f:
            text = f.read()
        symbols += re.findall("variable (\w+)", text)
    unique_symbols, counts = np.unique(symbols, return_counts=True)
    order = np.argsort(-counts)

    return unique_symbols[order], counts[order]

'''
Digital calc
'''
def convert_analog_to_digital(analog_data, thresh=.3):
    '''
    This function takes analog data and converts it to digital data given a 
    threshold. It scales the analog to between 0 and 1 and uses thres as a 

    Args: 
        analog_data (nt, nch): Time series array of analog data
        thresh (float, optional): Minimum threshold value to use in conversion

    Returns:
        (nt, nch): Array of 1's or 0's indicating if the analog input was above threshold  
    '''
    # Scale data between 0 and 1 so that threshold is a percentange
    minval = np.min(analog_data)
    maxval = np.max(analog_data)

    analog_data_scaled = (analog_data - minval)/maxval

    # Initialize digital_data
    digital_data = np.empty(analog_data_scaled.shape) # Default to empty 
    digital_data[:] = np.nan

    # Set any value less than the threshold to be 0
    digital_data[analog_data_scaled < thresh] = 0

    # Set any value greater than threshold to be 0
    digital_data[analog_data_scaled >= thresh] = 1

    # Check that there are no nan values in output data

    return digital_data

def detect_edges(digital_data, samplerate, rising=True, falling=True, check_alternating=True):
    '''
    Finds the timestamp and corresponding value of all the bit flips in data. Assumes 
    the first element in data isn't a transition

    By default, also enforces that rising and falling edges must alternate, always taking the
    last edge as the most valid one. For example::

        >>> data = [0, 0, 3, 0, 3, 2, 2, 0, 1, 7, 3, 2, 2, 0]
        >>> ts, values = detect_edges(data, fs)
        >>> print(values)
        [3, 0, 3, 0, 7, 0]

    Args:
        digital_data (ntime x 1): masked binary data array
        samplerate (int): sampling rate of the data used to calculate timestamps
        rising (bool, optional): include low to high transitions
        falling (bool, optional): include high to low transitions
        check_alternating (bool, optional): if True, enforces that rising and falling
            edges must be alternating

    Returns:
        tuple: tuple containing:
            | **timestamps (nbitflips):** when the bits flipped
            | **values (nbitflips):** corresponding values for each change
    '''

    digital_data = np.squeeze(np.uint64(digital_data)) # important conversion for binary math
    rising_idx = (~digital_data[:-1] & digital_data[1:]) > 0 # find low->high transitions
    falling_idx = (~digital_data[1:] & digital_data[:-1]) > 0

    # Find any non-alternating edges
    invalid = np.zeros((len(digital_data)-1,), dtype='?')
    if check_alternating:
        all_edges = np.where(rising_idx | falling_idx)[0]
        next_edge_rising = True
        for idx in range(len(all_edges)):
            this_idx = all_edges[idx]
            if next_edge_rising and rising_idx[this_idx]:
                # Expected rising and found rising
                next_edge_rising = False 
            elif not next_edge_rising and falling_idx[this_idx]:
                # Expected falling and found falling
                next_edge_rising = True 
            elif idx > 0: # skip the first edge since there is no previous edge
                # Unexpected; there must be an extra edge somewhere.
                # We will count this one as valid and the previous one as invalid
                prev_idx = all_edges[idx-1]
                invalid[prev_idx] = True
    
    # Assemble final index    
    logical_idx = np.zeros((len(digital_data)-1,), dtype='?')
    if rising:
        logical_idx |= rising_idx
    if falling:
        logical_idx |= falling_idx
    logical_idx &= np.logical_not(invalid)
    logical_idx = np.insert(logical_idx, 0, False) # first element never a transition

    time = np.arange(np.size(digital_data))/samplerate
    return time[logical_idx], digital_data[logical_idx]

def mask_and_shift(data, bit_mask):
    '''
    Apply bit mask and shift data to the least significant set bit in the mask. 
    For example,
    mask_and_shift(0001000011110000, 1111111100000000) => 00010000
    mask_and_shift(0001000011110000, 0000000011111111) => 11110000

    Args:
        data (ntime): digital data
        bit_mask (int): which bits to filter

    Returns:
        (nt): masked and shifted data
    '''

    return np.bitwise_and(data, bit_mask) >> find_first_significant_bit(bit_mask)

def find_first_significant_bit(x):
    '''
    Find first significant big. Returns the index, counting from 0, of the
    least significant set bit in x. Helper function for mask_and_shift

    Args:
        x (int): a number

    Returns:
        int: index of first significant nonzero bit
    '''
    return (x & -x).bit_length() - 1 # no idea how it works! thanks stack overflow --LRS

def convert_channels_to_mask(channels):
    '''
    Helper function to take a range of channels into a bitmask

    Args:
        channels (int array): 0-indexed channels to be masked
    
    Returns:
        int: binary mask of the given channels
    '''
    try:
        # Range of channels
        _ = iter(channels)
        channels = np.array(channels)
        flags = np.zeros(64, dtype=int)
        flags[channels] = 1
        return int(np.dot(np.array([2**i for i in range(64)]), flags))
    except:
        
        # Single channel
        return int(1 << channels)

def convert_digital_to_channels(data_64_bit):
    '''
    Converts 64-bit digital data from eCube into channels.

    Args:
        data_64_bit (n): masked 64-bit data, little-endian

    Returns:
        (n, 64): where channel 0 is least significant bit
    '''

    # Take the input, split into bytes, then unpack each byte, all little endian
    packed = np.squeeze(np.uint64(data_64_bit)) # required conversion to unsigned int
    unpacked = np.unpackbits(packed.view(np.dtype('<u1')), bitorder='little')
    return unpacked.reshape((packed.size, 64))
    
def get_edges_from_onsets(onsets, pulse_width):
    '''
    This function calculates the values and timepoints corresponding to a given time series 
    of pulse onsets (timestamp corresponding to the rising edge of a pulse). 
    Args:
        onsets (nonsets): Time point corresponding to a pulse onset. 
        pulse_width (float): Pulse duration 
    Returns:
        tuple: tuple containing:
            | **timestampes (2*nonsets + 1):** Timestamps of the rising and falling edges. Always starts at 0.
            | **values (2*nonsets + 1):** Values corresponding to the output timestamps.
    '''
    timestamps = np.zeros((1+len(onsets)*2,))
    values = np.zeros((1+len(onsets)*2,))
    for t in range(len(onsets)):
        timestamps[1+2*t] = onsets[t]
        values[1+2*t] = 1
        timestamps[2+2*t] = onsets[t]+pulse_width
        values[2+2*t] = 0
    return timestamps, values

def get_pulse_edge_times( digital_data, samplerate ):

    """get_pulse_edge_times

    Args:
        digital_data (nt, 1): array of data from ecube digital panel
        samplerate (numeric): data sampling rate (Hz)

    Returns:
        edge_times (npulse, 2): start and end times from each detected pulse
    """

    edge_times, edge_val = detect_edges(digital_data, samplerate)
    start_idx = np.where(edge_val == 1)[0][0]
    end_idx = np.where(edge_val == 0)[0][-1]
    edge_times = edge_times[start_idx:(end_idx+1)]
    edge_val = edge_val[start_idx:(end_idx+1)]
    edge_pairs = edge_times.reshape(-1,2)

    return edge_pairs

def compute_pulse_duty_cycles( edge_pairs ):

    """compute_pulse_duty_cycles

    Args:
        edge_pairs (npulse, 2): start, end times from a series of pulses

    Returns:
        duty_cycle (npulse): duty cycle of each pulse. Pulse period assumed to be constant.
    """

    pulse_times = edge_pairs[:,0]
    pulse_period = np.diff(pulse_times,axis=0)
    duty_cycle = np.squeeze(np.diff(edge_pairs,axis=-1))/pulse_period[0]

    return duty_cycle

def max_repeated_nans(a):
    '''
    Utility to calculate the maximum number of consecutive nans

    Args:
        a (ndarray): input sequence

    Returns:
        int: max consecutive nans
    '''
    mask = np.concatenate(([False],np.isnan(a),[False]))
    if ~mask.any():
        return 0
    else:
        idx = np.nonzero(mask[1:] != mask[:-1])[0]
        return (idx[1::2] - idx[::2]).max()

